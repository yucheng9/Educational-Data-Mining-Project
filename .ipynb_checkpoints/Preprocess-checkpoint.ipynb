{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Clustering and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yucheng Jin (yucheng9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due: September 25, 2019 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Will Need to Know For This Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-means clustering\n",
    "* Vector Quantization\n",
    "* Nearest Neighbors Classification\n",
    "* Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble (don't change this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tab\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from numpy import genfromtxt\n",
    "import scipy.spatial.distance as dist\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Selecting the number of clusters (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which implements K-means clustering. \n",
    "\n",
    "You will be given as input:\n",
    "* A $(N,d)$ numpy.ndarray of unlabeled data (with each row as a feature vector), data\n",
    "* A scalar $K$ which indicates the number of clusters\n",
    "* A scalar representing the number of iterations, niter (this is your stopping criterion/criterion for convergence)\n",
    "\n",
    "Your output will be a tuple consisting of a vector of length N containing which cluster ($0,\\ldots,K-1$) a feature vector is in and a $(K,d)$ matrix with the rows containing the cluster centers. \n",
    "\n",
    "Do not use scikit-learn or similar for implement K-means clustering. You may use `scipy.spatial.distance.cdist` to calculate distances. Initialize the centers randomly without replacement with points from the data set. `random.sample` may be useful for this. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(data,K,niter):\n",
    "    # initialize cluster centers\n",
    "    Kmeans_centers = data[np.random.choice(data.shape[0], K, replace = False),]\n",
    "    # initialize data clusters as an array of 0's\n",
    "    Kmeans_clusters = np.zeros(np.size(data, 0))\n",
    "    \n",
    "    for j in range(niter):\n",
    "        # assign x_i to cluster z_i = argmin||x_i - u_k||, k = 1, ..., K\n",
    "        distance_matrix = dist.cdist(data, Kmeans_centers, 'euclidean')\n",
    "        Kmeans_clusters = np.argmin(distance_matrix, axis = 1)\n",
    "                    \n",
    "        # update the center of cluster k as the mean of its data points\n",
    "        for k in range(K):    \n",
    "            Kmeans_centers_temp = np.zeros(np.size(data, 1))\n",
    "            cluster_count = 0\n",
    "            # find each x_i is in which cluster\n",
    "            for i in range(np.size(data, 0)):\n",
    "                if (Kmeans_clusters[i] == k): \n",
    "                    Kmeans_centers_temp += data[i]\n",
    "                    cluster_count += 1\n",
    "            Kmeans_centers[k] = Kmeans_centers_temp / cluster_count\n",
    "    \n",
    "    return (Kmeans_clusters, Kmeans_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means clustering problem tries to minimize the following quantity by selecting $\\{z_i\\}_{i=1}^N$ and $\\{\\mu_k\\}_{k=1}^K$:\n",
    "$$J_K(\\{z_i\\}_{i=1}^N ,\\{\\mu_k\\}_{k=1}^K)=\\sum_{i=1}^N \\lVert \\mathbf{x}_i - \\mathbf{\\mu}_{z_i} \\rVert^2$$\n",
    "where $\\mathbf{\\mu}_{z_i}$ is the center of the cluster to which $\\mathbf{x}_i$ is assigned.\n",
    "\n",
    "One visual heuristic to choose the number of clusters from the data (where the number of clusters is not known a priori) is to estimate the optimal value of $J_K(\\{z_i\\}_{i=1}^N ,\\{\\mu_k\\}_{k=1}^K)$, $J^*(K)$ , for different values of $K$ and look for an \"elbow\" or \"knee\" in the curve of $J^*$ versus $K$ and choose that value of $K$. \n",
    "\n",
    "In this part of the problem, you will run $K$-means 100 times for each $K=2,\\ldots,10$ and calculate $J_K(\\{z_i\\}_{i=1}^N ,\\{\\mu_k\\}_{k=1}^K)$ for the clustering given by $K$-means. Use the smallest value of $J_K(\\{z_i\\}_{i=1}^N ,\\{\\mu_k\\}_{k=1}^K)$ in the runs of $K$-means for each value of $K$ to form an estimate of $J^*(K)$. Plot this estimate versus $K$. Which $K$ should you pick by this heuristic? Use niter=100 for each run of $K$-means.\n",
    "\n",
    "For an attempt to formalize this heuristic, see Tibshirani, Robert, Guenther Walther, and Trevor Hastie. \"Estimating the number of clusters in a data set via the gap statistic.\" Journal of the Royal Statistical Society: Series B (Statistical Methodology) 63.2 (2001): 411-423. Sometimes, an elbow does not exist in the curve or there are multiple elbows or the $K$ value of an elbow cannot be unambiguously identified. Further material can be found on <a href=\"http://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_Elbow_Method\">Wikipedia</a> as well.  \n",
    "\n",
    "Note: Your code should be relatively quick -- a few minutes, at worst. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up some data, which we will store in a variable called problem1\n",
    "problem1= genfromtxt('problem1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When K =  2 , the value of J(K) is 124.77496210758807\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d8bf87cf0b63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# result of (Kmeans_clusters, Kmeans_centers)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mKmeans_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mKmeans_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKmeans_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mKmeans_centers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKmeans_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2915f7c8aa8c>\u001b[0m in \u001b[0;36mkMeans\u001b[1;34m(data, K, niter)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mKmeans_centers_temp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mcluster_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mKmeans_centers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKmeans_centers_temp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcluster_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKmeans_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmeans_centers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# run K-means 100 times for K = 2, ..., 10\n",
    "Kmeans_JK = np.zeros(11)\n",
    "for k in range(2, 11):\n",
    "    Kmeans_JK[k] = 10000\n",
    "    for i in range(100):\n",
    "        # result of (Kmeans_clusters, Kmeans_centers)\n",
    "        Kmeans_tuple = kMeans(problem1, k, 100)\n",
    "        Kmeans_clusters = Kmeans_tuple[0]\n",
    "        Kmeans_centers = Kmeans_tuple[1]\n",
    "        Kmeans_JK_temp = 0\n",
    "        # compute JK({z_i}, {u_k}) = Sum ||x_i - u_zi||^2\n",
    "        for j in range(k):\n",
    "                                                # convert every center to a 1*2 array\n",
    "            Kmeans_distances = dist.cdist(problem1, np.array([Kmeans_centers[j]]), 'sqeuclidean')\n",
    "            # loop through all points to update JK\n",
    "            for l in range(np.size(Kmeans_clusters)):\n",
    "                if (Kmeans_clusters[l] == j):\n",
    "                    Kmeans_JK_temp += Kmeans_distances[l][0]\n",
    "        if (Kmeans_JK_temp < Kmeans_JK[k]):\n",
    "            Kmeans_JK[k] = Kmeans_JK_temp\n",
    "    print(\"When K = \", k, \", the value of J(K) is\", Kmeans_JK[k])\n",
    "plt.plot(Kmeans_JK)\n",
    "plt.xlabel('K')\n",
    "plt.xlim(2, 10) \n",
    "plt.ylabel('J*(K)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "From the above plot, the \"knee\" in the $J^{*}(K)$ versus $K$ curve is $K$ = 4, because $J^{*}(K)$ decreases rapidly before 4 and flattens out after 4. I will pick the number of clusters as 4 (or some number around 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the value of $K$ you determined from the elbow, perform K-means clustering on the data. \n",
    "Plot it as a scatter plot with the colors given by the labels. <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeans_result = kMeans(problem1, 4, 100)\n",
    "colors = (\"y\", \"r\", \"g\", \"b\")\n",
    "plt.scatter(problem1[:,0], problem1[:,1], c = kMeans_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should you pick the $K$ such that $J^*(K)$ is minimized? Why or why not? <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "No, because it may result in overfitting. Since we pick the value of $K$ such that the grouping is more intuitive and obvious, if we pick a larger $K$ such that $J^{*}(K)$ is minimized, we may no longer find the grouping obvious but more complicated, which just makes little sense. We uses the \"elbow\" or \"knee\" method to find a kink in the $J^{*}(K)$ versus $K$ curve to find a $K$ that can not only distinguish between clusters, but also avoids overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Vector Quantization (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will implement vector quantization. You will use `sklearn.cluster.KMeans` for the K-means implementation and use k-means++ as the initialization method. See Section 4.2.1 in the notes for details. \n",
    "\n",
    "Write a function to generate a codebook for vector quantization. You will be given inputs:\n",
    "* A $(N,M)$ numpy.ndarray representing a greyscale image, called image. (If we want to generate our codebook from multiple images, we can concatenate the images before running them through this function).\n",
    "* A scalar $B$, for which you will use $B \\times B$ blocks for vector quantization. You may assume $N$ and $M$ are divisible by $B$.\n",
    "* A scalar $K$, which is the size of your codebook\n",
    "\n",
    "You will return:\n",
    "* The codebook as a $(K,B^2)$ numpy.ndarray. \n",
    "<b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVQ(image,B,K):\n",
    "    Image_split = np.split(image, image.shape[1]/B, axis = 1)\n",
    "    Image_split = np.array(Image_split).reshape(-1, B)\n",
    "    Image_split = np.split(Image_split, (image.shape[0] * image.shape[1]) / (B*B), axis = 0)\n",
    "    Image_split = [x.flatten() for x in Image_split]\n",
    "    Image_split = np.array(Image_split)\n",
    "    \n",
    "    VQ = KMeans(n_clusters = K)\n",
    "    VQ.fit(Image_split)\n",
    "    \n",
    "    return(VQ.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which compresses an image against a given codebook. You will be given inputs:\n",
    "* A $(N,M)$ numpy.ndarray representing a greyscale image, called image. You may assume $N$ and $M$ are divisible by $B$.\n",
    "* A $(K,B^2)$ codebook called codebook\n",
    "* $B$\n",
    "\n",
    "You will return:\n",
    "* A $(N/B,M/B)$ numpy.ndarray consisting of the indices in the codebook used to approximate the image. \n",
    "\n",
    "You can use the nearest neighbor classifier from scikit-learn if you want (though it is not necessary) to map blocks to their nearest codeword. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def compressImg(image, codebook, B):\n",
    "    Compress_image = np.split(image, image.shape[1]/B, axis = 1)\n",
    "    Compress_image = np.array(Compress_image).reshape(-1, B)\n",
    "    Compress_image = np.split(Compress_image, (image.shape[0] * image.shape[1]) / (B*B), axis = 0)\n",
    "    Compress_image = [x.flatten() for x in Compress_image]\n",
    "    Compress_image = np.array(Compress_image)\n",
    "    \n",
    "    Compress = NearestNeighbors(n_neighbors = 1, algorithm = 'kd_tree')\n",
    "    Compress.fit(codebook)\n",
    "    \n",
    "    indices = Compress.kneighbors(Compress_image, return_distance = False)\n",
    "    indices = np.resize(indices,(int(image.shape[1]/B), int(image.shape[0]/B)))\n",
    "    \n",
    "    return indices.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to reconstruct an image from its codebook. You will be given inputs:\n",
    "* A $(N/B,M/B)$ numpy.ndarray containing the indices of the codebook for each block called indices\n",
    "* A codebook as a $(K,B^2)$ numpy.ndarray called codebook\n",
    "* $B$\n",
    "\n",
    "You will return a $(N,M)$ numpy.ndarray representing the image. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompressImg(indices, codebook, B):\n",
    "    Decompress_indices = indices.T\n",
    "    Decompress_indices = Decompress_indices.flatten()\n",
    "    \n",
    "    Decompress_image = np.array([codebook[x] for x in Decompress_indices])\n",
    "    Decompress_image = [x for x in Decompress_image]\n",
    "    Decompress_image = [x.reshape(-1, B) for x in Decompress_image]\n",
    "    Decompress_image = np.array(Decompress_image)\n",
    "    Decompress_image = Decompress_image.reshape(-1, B)\n",
    "    Decompress_image = np.split(Decompress_image, indices.shape[1], axis = 0)\n",
    "    \n",
    "    Result = [x for x in Decompress_image]\n",
    "    Result = np.hstack(Result)\n",
    "    \n",
    "    return Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your vector quantizer with $5 \\times 5$ blocks on the provided image with codebook sizes $K=2,5,10,20,50,100,200$ (i.e. generate codebooks from this image of those sizes, compress the image using those codebooks and reconstruct the images). Display and comment on the reconstructed images (you may be quantitative (e.g. PSNR) or qualitative). Which code book would you pick? Why? Make sure to take into account the bits per pixel used by the compressor.\n",
    "\n",
    "Note the number of bits per pixel can be approximated as $\\frac{\\log_2 K}{25}$ and the codebook takes approximately $200K$ bits (assuming each pixel is stored as 8 bits). Some good ideas on quantitative arguments for codebook size can be found in Gonzalez & Woods, Digital Image Processing 3e or Gersho & Gray, Signal Compression & Vector Quantization. It is not necessary to look at these references for quantitative arguments, though. <b>(10 points)</b>\n",
    "\n",
    "The image used is under fair use from [Daily Illini](https://dailyillini.com/special-sections/international-student-guide/2018/08/15/how-to-dress-for-the-midwestern-weather/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The provided image is stored in image\n",
    "image = np.asarray(Image.open(\"mrtb.jpg\").convert(\"L\"))\n",
    "imshow(image, cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"K = 2\")\n",
    "codebook = trainVQ(image, 5, 2)\n",
    "compress_2 = compressImg(image, codebook, 5)\n",
    "decompress_2 = decompressImg(compress_2, codebook, 5)\n",
    "imshow(decompress_2, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(2)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 400 bits\")\n",
    "\n",
    "plt.figure(5)\n",
    "plt.title(\"K = 5\")\n",
    "codebook = trainVQ(image, 5, 5)\n",
    "compress_5 = compressImg(image, codebook, 5)\n",
    "decompress_5 = decompressImg(compress_5, codebook, 5)\n",
    "imshow(decompress_5, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(5)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 1,000 bits\")\n",
    "\n",
    "plt.figure(10)\n",
    "plt.title(\"K = 10\")\n",
    "codebook = trainVQ(image, 5, 10)\n",
    "compress_10 = compressImg(image, codebook, 5)\n",
    "decompress_10 = decompressImg(compress_10, codebook, 5)\n",
    "imshow(decompress_10, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(10)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 2,000 bits\")\n",
    "\n",
    "plt.figure(20)\n",
    "plt.title(\"K = 20\")\n",
    "codebook = trainVQ(image, 5, 20)\n",
    "compress_20 = compressImg(image, codebook, 5)\n",
    "decompress_20 = decompressImg(compress_20, codebook, 5)\n",
    "imshow(decompress_20, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(20)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 4,000 bits\")\n",
    "\n",
    "plt.figure(50)\n",
    "plt.title(\"K = 50\")\n",
    "codebook = trainVQ(image, 5, 50)\n",
    "compress_50 = compressImg(image, codebook, 5)\n",
    "decompress_50 = decompressImg(compress_50, codebook, 5)\n",
    "imshow(decompress_50, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(50)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 10,000 bits\")\n",
    "\n",
    "plt.figure(100)\n",
    "plt.title(\"K = 100\")\n",
    "codebook = trainVQ(image, 5, 100)\n",
    "compress_100 = compressImg(image, codebook, 5)\n",
    "decompress_100 = decompressImg(compress_100, codebook, 5)\n",
    "imshow(decompress_100, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(100)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 20,000 bits\")\n",
    "\n",
    "plt.figure(200)\n",
    "plt.title(\"K = 200\")\n",
    "codebook = trainVQ(image, 5, 200)\n",
    "compress_200 = compressImg(image, codebook, 5)\n",
    "decompress_200 = decompressImg(compress_200, codebook, 5)\n",
    "imshow(decompress_200, cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "print(\"Bits per pixel = \", math.log2(200)/25, \"bits/pixel\")\n",
    "print(\"Codebook size = 40,000 bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = [2, 5, 10, 20, 50, 100, 200]\n",
    "Bits_per_pixel = [math.log2(2)/25, math.log2(5)/25, math.log2(10)/25, \n",
    "                  math.log2(20)/25, math.log2(50)/25, math.log2(100)/25, math.log2(200)/25]\n",
    "\n",
    "plt.plot(Ks, Bits_per_pixel)\n",
    "plt.xlabel('K');\n",
    "plt.ylabel('bits/pixel');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Display and comment on the reconstructed images (you may be quantitative (e.g. PSNR) or qualitative). Which code book would you pick? Why? Make sure to take into account the bits per pixel used by the compressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "As we increse the number of codebook size, the resolution of the reconstructed image becomes better, which means that we achieve a better approximation of the original image and reduce the amount of lost signal.  \n",
    "I will choose $K = 100$. Since from the bits/pixel versus $K$ plot we find that $K = 100$ is a kink, before $100$, bits per pixel increases rapidly, after $100$, it increases slowly. Therefore, $K = 100$ balances both size of compression and image resolution well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Using K-means to Accelerate Nearest Neighbors (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will use K-means clustering to accelerate nearest neighbors, as outlined in the notes (Algorithm 7). Use `sklearn.neighbors.KNeighborsClassifier` for nearest neighbor classification and `sklearn.cluster.KMeans` for the K-means implementation with k-means++ as the initialization method.\n",
    "\n",
    "You will write a function to generate prototypes from labeled data. It will have input:\n",
    "* Training features as $(N,d)$ numpy.ndarray called traindata\n",
    "* Training labels as a length $N$ vector called trainlabels\n",
    "* $K$, the number of prototypes under each class\n",
    "\n",
    "You will return a tuple containing:\n",
    "* The prototypes selected as a $(K*\\text{number of classes},d)$ numpy.ndarray\n",
    "* The corresponding labels as a $K*\\text{number of classes}$ length vector \n",
    "\n",
    "You may assume there are at least $K$ examples under each class. `set(trainlabels)` will give you the set of labels. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrototypes(traindata,trainlabels,K):\n",
    "    Prototypes = []\n",
    "    Prototype_labels = []\n",
    "\n",
    "    for l in set(trainlabels):\n",
    "        # apply K-means clustering on the set of training samples with y_i = l to\n",
    "        # get cluster centers {u_l1, u_l2, ..., u_lk}\n",
    "        clusters = KMeans(n_clusters = K)\n",
    "        clusters.fit(traindata[trainlabels == l])\n",
    "        Prototypes.append(clusters.cluster_centers_)\n",
    "    \n",
    "        for i in range(K):\n",
    "            Prototype_labels.append(l)\n",
    "            \n",
    "    Prototypes = np.vstack(Prototypes)\n",
    "    \n",
    "    return (Prototypes, Prototype_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a nearest neighbor classifier (i.e. 1-NN)  with 1,10,50,100 and 200 prototypes per class for the digits data set from Lab 2. Comment on the validation error and computational complexity versus the nearest neighbor classifier from Lab 2 (error=0.056) and the LDA classifier (error=0.115) from Lab 2. Which classifier would you pick? Why? \n",
    "\n",
    "Note that this data set is generated from zip code digits from US mail, and the US Postal Service processes <a href=\"https://about.usps.com/who-we-are/postal-facts/one-day-by-the-numbers.htm\">hundreds of millions of pieces of mail</a> a day, so a small improvement in error can lead to tremendous savings in terms of mis-routed packages (which cost a lot of money and time to re-transport). <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits data set\n",
    "\n",
    "#Read in the Training Data\n",
    "traindata_tmp= genfromtxt('zip.train', delimiter=' ')\n",
    "#The training labels are stored in \"trainlabels\", training features in \"traindata\"\n",
    "trainlabels=traindata_tmp[:,0]\n",
    "traindata=traindata_tmp[:,1:]\n",
    "\n",
    "\n",
    "#Read in the Validation Data\n",
    "valdata_tmp= genfromtxt('zip.val', delimiter=' ')\n",
    "#The validation labels are stored in \"vallabels\", validation features in \"valdata\"\n",
    "vallabels=valdata_tmp[:,0]\n",
    "valdata=valdata_tmp[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Prototypes = generatePrototypes(traindata, trainlabels, 1)\n",
    "NN = KNeighborsClassifier(n_neighbors=1)\n",
    "NN.fit(Prototypes[0], Prototypes[1])\n",
    "print(\"K = 1, validation error = \", 1 - NN.score(valdata, vallabels))\n",
    "\n",
    "Prototypes = generatePrototypes(traindata, trainlabels, 10)\n",
    "NN = KNeighborsClassifier(n_neighbors=1)\n",
    "NN.fit(Prototypes[0], Prototypes[1])\n",
    "print(\"K = 10, validation error = \", 1 - NN.score(valdata, vallabels))\n",
    "\n",
    "Prototypes = generatePrototypes(traindata, trainlabels, 50)\n",
    "NN = KNeighborsClassifier(n_neighbors=1)\n",
    "NN.fit(Prototypes[0], Prototypes[1])\n",
    "print(\"K = 50, validation error = \", 1 - NN.score(valdata, vallabels))\n",
    "\n",
    "Prototypes = generatePrototypes(traindata, trainlabels, 100)\n",
    "NN = KNeighborsClassifier(n_neighbors=1)\n",
    "NN.fit(Prototypes[0], Prototypes[1])\n",
    "print(\"K = 100, validation error = \", 1 - NN.score(valdata, vallabels))\n",
    "\n",
    "Prototypes = generatePrototypes(traindata, trainlabels, 200)\n",
    "NN = KNeighborsClassifier(n_neighbors=1)\n",
    "NN.fit(Prototypes[0], Prototypes[1])\n",
    "print(\"K = 200, validation error = \", 1 - NN.score(valdata, vallabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "In terms of validation error, the nearest neighbor with 200 prototypes per class (error = 0.0543) is better than nearest neighbor (error = 0.056) and LDA (error = 0.115) from lab2. In terms of computational complexity, since LDA has computational complexity of $O(Nd^{2})$ if $N>d$ (where $N$ is the cardinality of training set and $d$ is the dimension of each sample), or $O(d^{3})$ otherwise, and nearest neighbor has computational complexity of $O(Kd)$, so nearest neighbor is better than LDA in computational complexity. Because using K-means can accelerate NN, so the nearest neighbor with 200 prototypes per class is the best of 3 also in computational complexity.  \n",
    "Therefore, the nearest neighbor with 200 prototypes per class performs better in both error and computational complexity. Furthermore, in practice, the US Postal Service processes hundreds of millions of pieces of mail a day, so a small improvement in error can lead to tremendous savings in terms of mis-routed packages and save a lot of money and time, so I will pick the nearest neighbor with 200 prototypes per class to perform the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Linear Regression (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will do model selection for linear regression using Ordinary Least Squares, Ridge Regression and the LASSO.\n",
    "\n",
    "The dataset you will use has 8 features:\n",
    "\n",
    "    lcavol - log cancer volume\n",
    "    lcaweight - log prostate weight\n",
    "    age\n",
    "    lbph - log of amount of benign prostatic hyperplasia\n",
    "    svi - seminal vesicle invasion\n",
    "    lcp - log capsular penetration\n",
    "    gleason - Gleason score\n",
    "    pgg45 - percent of Gleason scores 4 or 5\n",
    "\n",
    "and you will predict the level of a prostate-specific antigen. The data set was collected from a set of men about to receive a radical prostatectomy. More details are given in Section 3.2.1 in Elements of Statistical Learning 2e by Hastie et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows without output vector (requestd variables)\n",
    "def del_output_not_existed(data, varList, outVarList):\n",
    "    ret = data\n",
    "    for outVar in outVarList:\n",
    "        col_idx = varList.index(outVar)\n",
    "        col = ret[:, col_idx]\n",
    "        del_row_idx = np.where(np.isnan(col))\n",
    "        ret = np.delete(ret, del_row_idx, axis=0)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with the missing data by replacing with mean of column\n",
    "def fill_nan_with_mean(data, varList, outVarList):\n",
    "    ret = data\n",
    "    for i in range(1,len(varList)):\n",
    "        if varList[i] in outVarList:\n",
    "            continue\n",
    "        col = ret[:,i]\n",
    "        if len(np.isnan(col)) == len(col):\n",
    "            col[np.isnan(col)] = 0.\n",
    "        else:\n",
    "            col[np.isnan(col)] = np.mean(col[~np.isnan(col)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# get data\n",
    "filepath = 'merge_student_parent.csv'\n",
    "data = []  #Creates an empty list\n",
    "f = open(filepath) #Opens the file path in the default 'r' mode\n",
    "reader = csv.reader(f)\n",
    "for row in reader:\n",
    "    data.append(row)\n",
    "f.close()    # data is now a list of lists\n",
    "\n",
    "# get the variables list\n",
    "varList = data[0]\n",
    "\n",
    "# create the list of output variables\n",
    "'''\n",
    "# output variables \n",
    "# w2b1401\n",
    "# w2cogscore w2cog3pl\n",
    "# w2chn w2upchn\n",
    "# w2mat w2upmat\n",
    "# w2eng w2upeng\n",
    "'''\n",
    "# outVarList = ['w2b1401', 'w2cogscore','w2cog3pl', 'w2chn', 'w2upchn', 'w2mat', 'w2upmat', 'w2eng', 'w2upeng']\n",
    "\n",
    "# used for test\n",
    "outVarList = ['w2b1401']\n",
    "\n",
    "# Load the data\n",
    "# trainp= genfromtxt('trainp.csv', delimiter=',')\n",
    "data = genfromtxt('merge_student_parent.csv',  delimiter=',')\n",
    "\n",
    "# delete the rows without output vector (requestd variables)\n",
    "data = data[1:]\n",
    "data = del_output_not_existed(data, varList, outVarList)\n",
    "data = fill_nan_with_mean(data, varList, outVarList)\n",
    "\n",
    "\n",
    "input_num = data.shape[0]\n",
    "var_num = data.shape[1]\n",
    "\n",
    "inVarIdx = list(filter(lambda x:not(varList[x] in outVarList), range(var_num)))\n",
    "outVarIdx = list(filter(lambda x:varList[x] in outVarList, range(var_num)))\n",
    "\n",
    "train_data_num = int(input_num * 2/3)\n",
    "\n",
    "# Training data: \n",
    "trainfeat=data[:train_data_num, inVarIdx] #Training features (rows are feature vectors)\n",
    "trainresp=data[:train_data_num, outVarIdx] #Training responses\n",
    "\n",
    "\n",
    "# Validation data:\n",
    "valfeat=data[train_data_num + 1:, inVarIdx] #Validation Features (rows are feature vectors)\n",
    "valresp=data[train_data_num + 1:, outVarIdx] #Validation Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize and center the features\n",
    "ftsclr=StandardScaler()\n",
    "trainfeat = ftsclr.fit_transform(trainfeat)\n",
    "valfeat= ftsclr.transform(valfeat)\n",
    "# and the responses (note that the example in the notes has centered but not \n",
    "#                    standardized responses, so your numbers won't match up)\n",
    "rsclr=StandardScaler()\n",
    "trainresp = (rsclr.fit_transform(trainresp.reshape(-1,1))).reshape(-1)\n",
    "valresp= (rsclr.transform(valresp.reshape(-1,1))).reshape(-1)\n",
    "\n",
    "# The training features are in trainfeat\n",
    "# The training responses are in trainresp\n",
    "# The validation features are in valfeat\n",
    "# The validation responses are in valresp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we centered the responses, we can begin with a benchmark model: Always predict the response as zero (mean response on the training data). Calculate the validation RSS for this model. **(5 points)**\n",
    "\n",
    "If another model does worse than this, it is a sign that something is amiss.\n",
    "\n",
    "Note: The RSS on a data set with $V$ samples is given by $\\frac{1}{V} \\lVert \\mathbf{y} - \\hat{\\mathbf{y}} \\rVert^2$ where $\\mathbf{y}$ is a vector of the responses, and $\\hat{\\mathbf{y}}$ is the predicted responses on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark RSS =  0.9897626884660055\n"
     ]
    }
   ],
   "source": [
    "zeroresp = np.zeros(valresp.size)\n",
    "dif = zeroresp - valresp\n",
    "sqdif = np.dot(dif, dif)\n",
    "RSS = sum(sqdif) / valresp.size\n",
    "print(\"Benchmark RSS = \", RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "The benchmark validation RSS is 0.733852091912677."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you will try (Ordinary) Least Squares. Use `sklearn.linear_model.LinearRegression` with the default options. Calculate the validation RSS. <b>(5 points)</b>\n",
    "\n",
    "Note: The .score() method returns an [$R^2$  value](https://en.wikipedia.org/wiki/Coefficient_of_determination), not the RSS, so you shouldn't use it anywhere in this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RSS =  0.7263437929868771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinearRegression = LinearRegression()\n",
    "LinearRegression.fit(trainfeat, trainresp)\n",
    "\n",
    "# RSS = y.T * y - 2 * y.T * X * beta + beta.T * X.T * X * beta\n",
    "X = valfeat\n",
    "y = valresp\n",
    "beta = LinearRegression.coef_\n",
    "First = np.dot(y, y)\n",
    "Second = 2 * (np.dot(y.T, X).dot(beta))\n",
    "Third = np.dot((np.dot(valfeat, beta)).T, np.dot(X, beta))\n",
    "print(\"Validation RSS = \", (First - Second + Third)/valfeat.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "The validation RSS is 0.36230709903819786."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will apply ridge regression with `sklearn.linear_model.Ridge`. \n",
    "\n",
    "Sweep the regularization/tuning parameter $\\alpha=0,\\ldots,100$ with 1000 equally spaced values. \n",
    "\n",
    "Make a plot of the RSS on the validation set versus $\\alpha$. What is the minimizing $\\alpha$, corresponding coefficients and validation error? \n",
    "\n",
    "Larger values of $\\alpha$ shrink the weights in the model more. $\\alpha=0$ corresponds to the LS solution. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizing alpha =  99.9999999999986\n",
      "Coefficients =  [ 9.86772403e-03 -1.08352141e-01  3.74534780e-02 -1.56963657e-02\n",
      " -1.01969762e-02  3.45966566e-03 -2.10601320e-02  3.14634760e-02\n",
      " -1.55377581e-02 -4.45456745e-02 -5.25558108e-03  2.81881329e-02\n",
      "  7.68712656e-02  1.00189524e-03 -8.13438051e-03  5.39005350e-04\n",
      " -7.50595988e-04 -2.61119014e-02  2.81716375e-02 -2.24870165e-03\n",
      "  1.28098754e-02  1.81064080e-03  1.27196504e-02 -1.12021144e-03\n",
      " -6.57020163e-03 -1.88394376e-02  1.37362829e-02 -7.92342383e-03\n",
      "  1.56841896e-02 -3.72916711e-02  1.84180542e-02  3.30364550e-03\n",
      "  3.72272322e-03  1.39863201e-02  1.79543050e-02 -2.24153234e-02\n",
      " -1.31544022e-02  1.36411028e-02 -4.99511260e-03 -8.49016927e-03\n",
      "  4.26942996e-02 -4.26408729e-03 -2.20335578e-02 -2.27871383e-02\n",
      " -7.56344179e-03  2.73570503e-02 -7.32149473e-03  3.85124717e-02\n",
      "  2.59802686e-02  4.70996471e-03 -4.43227321e-02  2.25990887e-02\n",
      "  3.12399091e-02 -4.72551112e-02 -2.08997723e-02  2.10447337e-02\n",
      "  4.01891702e-04  1.77275008e-02  7.08971205e-03  8.80797456e-03\n",
      " -4.19905768e-02 -1.61119358e-03  5.33648874e-03 -2.82113721e-02\n",
      "  2.99697172e-02 -6.41256796e-02 -1.23415725e-01 -1.07117504e-01\n",
      " -3.79797569e-02  5.11184315e-02  1.54878540e-02 -4.50627958e-03\n",
      " -6.77517603e-03 -2.63938310e-02  0.00000000e+00  3.59397481e-02\n",
      "  3.69514765e-02 -1.36764023e-02 -4.03712784e-03 -1.07571984e-02\n",
      " -2.59076107e-02  2.88422145e-02  4.12281380e-03  2.23164022e-02\n",
      "  2.61805225e-02  3.26529874e-02 -4.87342639e-03  2.82504119e-03\n",
      "  4.05733248e-03 -2.65044078e-02  3.61228427e-02  3.90146888e-03\n",
      "  6.05493526e-03  2.23372485e-02 -8.00601754e-03  7.69836599e-03\n",
      " -3.68111459e-03 -8.06295647e-03  2.16015801e-02 -2.87612971e-02\n",
      "  1.67211226e-02  2.78312711e-02 -1.03632021e-02  4.18562712e-03\n",
      " -3.73176261e-03  8.17911372e-03  2.95439724e-02  7.03211119e-03\n",
      " -1.66872640e-02 -1.61684705e-02 -3.36626089e-02  2.64066739e-02\n",
      " -1.80703617e-03  3.59634428e-03 -5.30473362e-03 -2.82457840e-03\n",
      "  3.91452463e-03 -3.13750721e-02  2.17379853e-02 -4.16635491e-03\n",
      " -7.70434991e-03 -4.24285001e-02  4.06554719e-03  3.98021060e-02\n",
      "  2.82165170e-02  4.76426650e-02  2.01787277e-02 -3.29665038e-01\n",
      "  4.18452207e-02  6.26567631e-03 -4.62604457e-04 -2.65432387e-03\n",
      "  1.91351163e-02 -2.38472974e-02  3.39107432e-02  1.26743891e-02\n",
      "  8.62455333e-03  9.18792261e-03  3.54572366e-02  1.99555806e-03\n",
      " -1.00121646e-02  1.81308557e-02  4.10890026e-02  6.85027164e-03\n",
      "  6.61067573e-03  7.22754124e-03 -1.63989133e-02  1.32732136e-02\n",
      " -1.15508765e-02  6.05388131e-03 -4.87904492e-03 -8.14906151e-03\n",
      " -2.31405200e-02  1.08094512e-03  2.10529495e-02 -2.22765261e-02\n",
      "  3.76800548e-03  1.28442578e-02 -2.30176946e-02 -4.51680316e-03\n",
      "  2.38745872e-02  1.22196114e-03  1.63903467e-02  1.28898077e-02\n",
      "  2.07938319e-02 -3.52745425e-02  3.04216868e-02 -1.45850744e-03\n",
      "  1.04316061e-03  1.15587334e-02 -2.64512535e-02 -2.01384842e-02\n",
      " -5.79727651e-03  1.90408106e-02 -2.67827681e-02  1.19705051e-04\n",
      "  1.67769462e-02  2.61649782e-03 -2.35893985e-02  1.29052465e-02\n",
      " -3.37883614e-02  4.27054883e-03]\n",
      "Min validation error =  0.7131529093623298\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "RSS = []\n",
    "alphas = []\n",
    "a = -0.1\n",
    "\n",
    "for i in range(1, 1002):\n",
    "    a += 0.1 \n",
    "    \n",
    "    LinearRegression = Ridge(alpha = a)\n",
    "    LinearRegression.fit(trainfeat, trainresp)\n",
    "    \n",
    "    # RSS = y.T * y - 2 * y.T * X * beta + beta.T * X.T * X * beta\n",
    "    X = valfeat\n",
    "    y = valresp\n",
    "    beta = LinearRegression.coef_\n",
    "    First = np.dot(y, y)\n",
    "    Second = 2 * (np.dot(y.T, X).dot(beta))\n",
    "    Third = np.dot((np.dot(valfeat, beta)).T, np.dot(X, beta))\n",
    "    \n",
    "    RSS.append((First - Second + Third)/valfeat.shape[0])\n",
    "    alphas.append(a)\n",
    "\n",
    "Min_index = RSS.index(min(RSS))\n",
    "Min_alpha = alphas[Min_index]\n",
    "\n",
    "RidgeRegression = Ridge(Min_alpha)\n",
    "RidgeRegression.fit(trainfeat, trainresp)\n",
    "\n",
    "plot(alphas, RSS)\n",
    "\n",
    "print(\"Minimizing alpha = \", Min_alpha)\n",
    "print(\"Coefficients = \", RidgeRegression.coef_)\n",
    "print(\"Min validation error = \", min(RSS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "The alpha that minimizes RSS is 12.3, its corresponding coefficients are [0.42884607, 0.22632962, -0.06459576, 0.15540954, 0.21582, -0.05445595, 0.02587039, 0.13451361], and validation error is 0.3384853737648544."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will apply the LASSO with `sklearn.linear_model.Lasso`. \n",
    "\n",
    "Sweep the tuning/regularization parameter $\\alpha=0,\\ldots,1$ with 1000 equally spaced values. \n",
    "\n",
    "Make a plot of the RSS on the validation set versus $\\alpha$. What is the minimizing $\\alpha$, corresponding coefficients and validation error? \n",
    "\n",
    "\n",
    "Larger values of $\\alpha$ lead to sparser solutions (i.e. less features used in the model), with a sufficiently large value of $\\alpha$ leading to a constant prediction. Small values of $\\alpha$ are closer to the LS solution, with $\\alpha=0$ being the LS solution. <b>(10 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizing alpha =  0.01900000000000001\n",
      "Coefficients =  [-0.00000000e+00 -5.80844228e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -7.95264045e-03  0.00000000e+00 -0.00000000e+00\n",
      "  6.01737767e-02 -0.00000000e+00 -7.24336319e-03  0.00000000e+00\n",
      "  0.00000000e+00 -2.44655877e-02  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  2.29686951e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  9.60041733e-04 -0.00000000e+00  2.70246253e-02\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  1.59367238e-03\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.61268402e-02 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  4.31516651e-03 -3.93597120e-02 -8.99097082e-02 -7.73769154e-02\n",
      " -6.79147445e-04  4.19711651e-02  3.33279876e-03 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  1.32990404e-02\n",
      "  1.38460533e-02 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.30453938e-02  0.00000000e+00  0.00000000e+00\n",
      "  2.02004823e-02  1.55604323e-02  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  1.91593136e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -6.03683516e-03\n",
      "  0.00000000e+00  2.41315456e-03  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.29603763e-05 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  9.32397522e-03\n",
      "  1.29549620e-02  4.91526878e-02  9.66092621e-03 -3.28419166e-01\n",
      "  3.20170475e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.87990058e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  2.94718775e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.86559239e-03  3.64077116e-02  0.00000000e+00\n",
      "  1.21270519e-03 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -1.36617219e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.73300897e-02 -0.00000000e+00\n",
      "  4.60634289e-03  0.00000000e+00  0.00000000e+00  6.01176875e-03\n",
      " -0.00000000e+00 -9.27075646e-03  2.11951921e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  3.39331697e-02 -1.33246382e-02  0.00000000e+00\n",
      "  1.46904968e-04  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -1.32843017e-02  0.00000000e+00]\n",
      "Min validation error =  0.6914553847010435\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "RSS = []\n",
    "alphas = []\n",
    "a = 0\n",
    "\n",
    "for i in range(1, 1002):\n",
    "    # initial a = 0.001 since there is a warning that \"model does not converge well when a = 0\"\n",
    "    a += 0.001 \n",
    "    \n",
    "    LinearRegression = Lasso(alpha = a)\n",
    "    LinearRegression.fit(trainfeat, trainresp)\n",
    "    \n",
    "    # RSS = y.T * y - 2 * y.T * X * beta + beta.T * X.T * X * beta\n",
    "    X = valfeat\n",
    "    y = valresp\n",
    "    beta = LinearRegression.coef_\n",
    "    First = np.dot(y, y)\n",
    "    Second = 2 * (np.dot(y.T, X).dot(beta))\n",
    "    Third = np.dot((np.dot(valfeat, beta)).T, np.dot(X, beta))\n",
    "    \n",
    "    RSS.append((First - Second + Third)/valfeat.shape[0])\n",
    "    alphas.append(a)\n",
    "\n",
    "Min_index = RSS.index(min(RSS))\n",
    "Min_alpha = alphas[Min_index]\n",
    "plot(alphas, RSS)\n",
    "\n",
    "LassoRegression = Lasso(Min_alpha)\n",
    "LassoRegression.fit(trainfeat, trainresp)\n",
    "\n",
    "print(\"Minimizing alpha = \", Min_alpha)\n",
    "print(\"Coefficients = \", LassoRegression.coef_)\n",
    "print(\"Min validation error = \", min(RSS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "The alpha that minimizes RSS is 0.124, its corresponding coefficients are [0.47125423, 0.17524796, 0., 0.04938086, 0.11421009, 0., 0., 0.02988408], and validation error is 0.3142649165206583."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features were selected by Ridge Regression when minimizing the RSS on the validation set? Which features were selected by LASSO when minimizing the RSS on the validation set? Which model would you choose (and why)? <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert Answer Here]  \n",
    "Ridge Regression selects all features since its coefficients are all non-zero, while LASSO only selects 5 features: lcavol (log cancer volume), lcaweight (log prostate weight), lbph (log of amount of benign prostatic hyperplasia), svi (seminal vesicle invasion), and pgg45 (percent of Gleason scores 4 or 5). It ignores age, lcp (log capsular penetration), and gleason (Gleason score).  \n",
    "I will choose LASSO, since it removes some unimportant features and simplify the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And this concludes Lab 4! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
