{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression, Ridge & Lasso\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import neighbors\n",
    "from numpy import genfromtxt\n",
    "import scipy.spatial.distance as dist\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SVM, Logistic Regression\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# get data\n",
    "filepath = 'DummyData.csv'\n",
    "data = []  \n",
    "f = open(filepath) \n",
    "reader = csv.reader(f)\n",
    "for row in reader:\n",
    "    data.append(row)\n",
    "f.close()  \n",
    "\n",
    "# Get the variables list\n",
    "varList = data[0]\n",
    "\n",
    "# Create the list of output variables\n",
    "'''\n",
    "# output variables \n",
    "# w2b1401\n",
    "# w2cogscore w2cog3pl\n",
    "# w2chn w2upchn\n",
    "# w2mat w2upmat\n",
    "# w2eng w2upeng\n",
    "'''\n",
    "# outVarList = ['w2b1401', 'w2cogscore','w2cog3pl', 'w2chn', 'w2upchn', 'w2mat', 'w2upmat', 'w2eng', 'w2upeng']\n",
    "\n",
    "# Used for test\n",
    "UsedForTest = ['w2stdtotal']\n",
    "\n",
    "# Load the data\n",
    "# trainp = genfromtxt('trainp.csv', delimiter=',')\n",
    "data = genfromtxt('Today.csv',  delimiter=',')\n",
    "\n",
    "input_num = data.shape[0]\n",
    "var_num = data.shape[1]\n",
    "\n",
    "# Take 2/3 data as train set, 1/3 as test set\n",
    "train_data_num = int(input_num * 2/3)\n",
    "\n",
    "# Without cross-validation\n",
    "\n",
    "# Training data: \n",
    "trainfeat=data[:train_data_num, :] #Training features (rows are feature vectors)\n",
    "trainresp=data[:train_data_num, :] #Training responses\n",
    "\n",
    "# Validation data:\n",
    "valfeat=data[train_data_num + 1:, :] #Validation Features (rows are feature vectors)\n",
    "valresp=data[train_data_num + 1:, :] #Validation Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(open('DummyData.csv'))\n",
    "data = data.dropna()                                                                               \n",
    "X = data.values[:,5:-1]\n",
    "Y = data.values[:,4]\n",
    "colnames = list(data.columns[5:-1])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lmodel = linear_model.LinearRegression()\n",
    "lmodel.fit(X_train, Y_train)\n",
    "lmodel.coef_\n",
    "lmodel.intercept_\n",
    "coef = [lmodel.intercept_]\n",
    "coef.extend(list(lmodel.coef_))\n",
    "cols = [\"interccept\"]\n",
    "cols.extend(colnames)\n",
    "coef = pd.DataFrame(coef, index = cols, columns = [\"coefficient\"])\n",
    "coef.to_csv(\"linear_reg_coef.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root of Mean Square Error \n",
    "train_err_l = np.sqrt(np.mean((lmodel.predict(X_train) - Y_train)**2))\n",
    "test_err_l =np.sqrt(np.mean((lmodel.predict(X_test) - Y_test)**2))\n",
    "train_var_pct_l = np.var(np.array(lmodel.predict(X_train))) / np.var(Y_train)\n",
    "test_var_pct_l = np.var(np.array(lmodel.predict(X_test))) / np.var(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29379590015079643, 0.32132174386808326)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_var_pct_l, test_var_pct_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6428677934077509, 0.6446420574518552)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err_l, test_err_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPRegressor as mlp\n",
    "\n",
    "Train_err_n = []\n",
    "Test_err_n = []\n",
    "for i in range(10,100,5):\n",
    "    nmodel=mlp(activation= 'logistic',learning_rate_init=0.005,\n",
    "               random_state=66, max_iter=1000, hidden_layer_sizes=(i))\n",
    "    nmodel.fit(X_train,Y_train)\n",
    "    Train_err_n.append(np.sqrt(np.mean((nmodel.predict(X_train) - Y_train)**2)))\n",
    "    Test_err_n.append(np.sqrt(np.mean((nmodel.predict(X_test) - Y_test)**2)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(10,100,5),Train_err_n)\n",
    "plt.title(\"Training Error of Neural Network\")\n",
    "plt.xlabel(\"Number of neurons\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"nn-train-err.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(range(10,100,5),Test_err_n)\n",
    "plt.title(\"Test Error of Neural Network\")\n",
    "plt.xlabel(\"Number of neurons\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"nn-test-err.png\")\n",
    "plt.close()\n",
    "\n",
    "### Results\n",
    "nmodel=mlp(activation= 'logistic',learning_rate_init=0.005,\n",
    "           random_state=66, max_iter=1000, hidden_layer_sizes=(40))\n",
    "nmodel.fit(X_train,Y_train)\n",
    "\n",
    "train_err_n = np.sqrt(np.mean((nmodel.predict(X_train) - Y_train)**2))\n",
    "test_err_n = np.sqrt(np.mean((nmodel.predict(X_test) - Y_test)**2))\n",
    "train_var_pct_n = np.var(np.array(nmodel.predict(X_train))) / np.var(Y_train)\n",
    "test_var_pct_n = np.var(np.array(nmodel.predict(X_test))) / np.var(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04967249583777655\n",
      "0.8459357037526326\n",
      "0.9907820836544687\n",
      "0.9232376763246279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor as mlp\n",
    "\n",
    "nnmodel=mlp(activation= 'logistic',learning_rate_init=0.005,\n",
    "           random_state=66, max_iter=1000, hidden_layer_sizes=(90))\n",
    "nnmodel.fit(X_train,Y_train)\n",
    "\n",
    "train_err_n = np.sqrt(np.mean((nnmodel.predict(X_train) - Y_train)**2))\n",
    "test_err_n = np.sqrt(np.mean((nnmodel.predict(X_test) - Y_test)**2))\n",
    "train_var_pct_n = np.var(np.array(nnmodel.predict(X_train))) / np.var(Y_train)\n",
    "test_var_pct_n = np.var(np.array(nnmodel.predict(X_test))) / np.var(Y_test)\n",
    "\n",
    "print(train_err_n)\n",
    "print(test_err_n)\n",
    "print(train_var_pct_n)\n",
    "print(test_var_pct_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# min_samples_split\n",
    "Train_err_t = []\n",
    "Test_err_t = []\n",
    "for i in range(2,500,4): \n",
    "    tmodel = tree.DecisionTreeRegressor(min_samples_split=i,random_state=66) \n",
    "    tmodel.fit(X_train,Y_train)\n",
    "    Train_err_t.append(np.sqrt(np.mean((tmodel.predict(X_train) - Y_train)**2)))\n",
    "    Test_err_t.append(np.sqrt(np.mean((tmodel.predict(X_test) - Y_test)**2)))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(2,500,4),Train_err_t)\n",
    "plt.title(\"Training Error of Decision Tree\")\n",
    "plt.xlabel(\"Min_Samples_Split\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"tree-train-err.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(range(2,500,4),Test_err_t)\n",
    "plt.title(\"Test Error of Decision Tree\")\n",
    "plt.xlabel(\"Min_Samples_Split\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"tree-test-err.png\")\n",
    "plt.close()\n",
    "\n",
    "# Results\n",
    "import graphviz \n",
    "\n",
    "# Select a best min_samples_split and random_state\n",
    "tmodel = tree.DecisionTreeRegressor(min_samples_split=162,random_state=66)\n",
    "tmodel.fit(X_train,Y_train)\n",
    "\n",
    "train_err_t = np.sqrt(np.mean((tmodel.predict(X_train) - Y_train)**2))\n",
    "test_err_t = np.sqrt(np.mean((tmodel.predict(X_test) - Y_test)**2))\n",
    "\n",
    "dot_data = tree.export_graphviz(tmodel, out_file=None) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "graph.save(\"tree.gv\")\n",
    "\n",
    "train_var_pct_t = np.var(np.array(tmodel.predict(X_train))) / np.var(Y_train)\n",
    "test_var_pct_t = np.var(np.array(tmodel.predict(X_test))) / np.var(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchengjin/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "\n",
    "Train_err_rf = []\n",
    "Test_err_rf = []\n",
    "Oob_err_rf = []\n",
    "\n",
    "for i in range(20,1000,20): \n",
    "    fmodel = rf(n_estimators=i, oob_score=True, random_state=66, n_jobs=3)\n",
    "    fmodel.fit(X_train,Y_train)\n",
    "    Train_err_rf.append(np.sqrt(np.mean((fmodel.predict(X_train) - Y_train)**2)))\n",
    "    Test_err_rf.append(np.sqrt(np.mean((fmodel.predict(X_test) - Y_test)**2)))\n",
    "    Oob_err_rf.append(fmodel.oob_score_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(20,1000,20),Train_err_rf)\n",
    "plt.title(\"Training Error of Random Forest\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"rf-train-err.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(range(20,1000,20), np.array(Oob_err_rf))\n",
    "plt.title(\"OOB Score of Random Forest\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"rf-oob-err.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(20,1000,20),Test_err_rf)\n",
    "plt.title(\"Test Error of Random Forest\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"rf-test-err.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22415209792433233\n",
      "0.24742397597863375\n",
      "0.6282805506274968\n",
      "0.5450012057253169\n",
      "0.2809824300209125\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "fmodel = rf(n_estimators=900, oob_score=True, random_state=66)\n",
    "fmodel.fit(X_train,Y_train)\n",
    "importance = fmodel.feature_importances_\n",
    "oob_score_f = fmodel.oob_score_\n",
    "train_err_f = np.sqrt(np.mean((fmodel.predict(X_train) - Y_train)**2))\n",
    "test_err_f = np.sqrt(np.mean((fmodel.predict(X_test) - Y_test)**2))\n",
    "train_var_pct_f = np.var(np.array(fmodel.predict(X_train))) / np.var(Y_train)\n",
    "test_var_pct_f = np.var(np.array(fmodel.predict(X_test))) / np.var(Y_test)\n",
    "\n",
    "print(oob_score_f)\n",
    "print(train_err_f)\n",
    "print(test_err_f)\n",
    "print(train_var_pct_f)\n",
    "print(test_var_pct_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = []\n",
    "coef.extend(list(importance))\n",
    "cols = []\n",
    "cols.extend(colnames)\n",
    "coef = pd.DataFrame(coef, index = cols, columns = [\"coefficient\"])\n",
    "coef.to_csv(\"rf_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchengjin/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py:1011: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor as bag\n",
    "\n",
    "Train_err_b = []\n",
    "Test_err_b = []\n",
    "Oob_err_b = []\n",
    "for i in range(20,500,10):  \n",
    "    bmodel = bag(n_estimators=i, oob_score=True, random_state=66, n_jobs=3)\n",
    "    bmodel.fit(X_train,Y_train)\n",
    "    Train_err_b.append(np.sqrt(np.mean((bmodel.predict(X_train) - Y_train)**2)))\n",
    "    Test_err_b.append(np.sqrt(np.mean((bmodel.predict(X_test) - Y_test)**2)))\n",
    "    Oob_err_b.append(bmodel.oob_score_)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(20,500,10),Train_err_b)\n",
    "plt.title(\"Train Error of Bagging\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"bagging-train-err.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(range(20,500,10),Test_err_b)\n",
    "plt.title(\"Test Error of Bagging\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"bagging-test-err.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(range(20,500,10),-np.array(Oob_err_b))\n",
    "plt.title(\"Oob Score of Bagging\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.savefig(\"bagging-oob-err.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
